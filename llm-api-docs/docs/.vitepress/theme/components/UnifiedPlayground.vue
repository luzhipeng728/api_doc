<template>
  <div class="unified-playground">
    <h2>ğŸ® ç»Ÿä¸€ API æµ‹è¯•å¹³å°</h2>

    <!-- ä¸‰æ å¸ƒå±€ -->
    <div class="three-column-layout">
      <!-- å·¦ä¾§: é…ç½®åŒº -->
      <div class="left-panel">
        <div class="panel-header">âš™ï¸ é…ç½®</div>

        <div class="config-section">
          <label class="config-label">é€‰æ‹©æ¨¡å‹:</label>
          <select v-model="selectedModel" class="config-select">
            <optgroup label="OpenAI - GPT ç³»åˆ—">
              <option value="gpt-4">GPT-4</option>
              <option value="gpt-4o">GPT-4o</option>
              <option value="gpt-5">GPT-5</option>
            </optgroup>
            <optgroup label="OpenAI - å›¾åƒç”Ÿæˆ">
              <option value="gpt-image-1">GPT-Image-1</option>
            </optgroup>
            <optgroup label="Claude">
              <option value="claude-sonnet-4-5-20250929">Claude Sonnet 4.5 (20250929)</option>
              <option value="claude-haiku-4-5-20251001">Claude Haiku 4.5 (20251001)</option>
            </optgroup>
            <optgroup label="Gemini">
              <option value="gemini-2.5-pro">Gemini 2.5 Pro</option>
              <option value="gemini-2.5-flash">Gemini 2.5 Flash</option>
              <option value="gemini-2.5-flash-image">Gemini 2.5 Flash Image</option>
            </optgroup>
          </select>
        </div>

        <div v-if="supportsTools" class="config-section">
          <label class="config-checkbox">
            <input type="checkbox" v-model="enableTools" />
            <span>å¯ç”¨å·¥å…·è°ƒç”¨</span>
          </label>
        </div>

        <div v-if="supportsStreaming" class="config-section">
          <label class="config-checkbox">
            <input type="checkbox" v-model="streamMode" />
            <span>æµå¼æ¨¡å¼</span>
          </label>
        </div>

        <div v-if="isImageModel" class="config-section">
          <label class="config-label">å›¾ç‰‡ä¸Šä¼ :</label>
          <input type="file" @change="handleImageUpload" accept="image/*" class="config-file" />
        </div>

        <div class="config-section">
          <label class="config-label">{{ promptLabel }}:</label>
          <textarea
            v-model="testPrompt"
            class="config-textarea"
            :placeholder="promptPlaceholder"
            rows="6"
          ></textarea>
        </div>

        <div class="config-section">
          <button class="btn btn-primary btn-block" @click="executeTest" :disabled="loading || !canExecute">
            <span v-if="!loading">â–¶ï¸ æ‰§è¡Œæµ‹è¯•</span>
            <span v-else>â³ æ‰§è¡Œä¸­...</span>
          </button>
        </div>
      </div>

      <!-- ä¸­é—´: ä»£ç åŒº -->
      <div class="middle-panel">
        <div class="panel-header">
          <span>ğŸ’» ä»£ç ç¤ºä¾‹</span>
          <div class="tab-switcher">
            <button
              class="tab-button"
              :class="{ active: codeType === 'python' }"
              @click="codeType = 'python'"
            >
              Python
            </button>
            <button
              class="tab-button"
              :class="{ active: codeType === 'curl' }"
              @click="codeType = 'curl'"
            >
              cURL
            </button>
          </div>
        </div>
        <div class="code-container">
          <CodeEditor
            v-model="currentCode"
            :language="editorLanguage"
            :read-only="true"
          />
        </div>
      </div>

      <!-- å³ä¾§: ç»“æœåŒº -->
      <div class="right-panel">
        <div class="panel-header">ğŸ“Š å“åº”ç»“æœ</div>

        <div class="result-container">
          <!-- æ— å“åº”æ—¶çš„å ä½ -->
          <div v-if="!response && streamChunks.length === 0 && !error" class="empty-state">
            <div class="empty-icon">ğŸš€</div>
            <p>ç‚¹å‡»"æ‰§è¡Œæµ‹è¯•"æŸ¥çœ‹å“åº”ç»“æœ</p>
          </div>

          <!-- å“åº”å±•ç¤º -->
          <div v-if="response" class="response-display">
            <h4>{{ responseTitle }}</h4>

            <!-- å¦‚æœæ˜¯å›¾ç‰‡å“åº”,æ˜¾ç¤ºå›¾ç‰‡é¢„è§ˆ -->
            <div v-if="responseImages.length > 0" class="image-preview-container">
              <div v-for="(img, index) in responseImages" :key="index" class="image-preview-item">
                <img :src="img.dataUrl" :alt="`ç”Ÿæˆçš„å›¾åƒ ${index + 1}`" class="generated-image" />
                <div class="image-info">
                  <span>{{ img.mimeType }}</span>
                  <span>{{ formatBytes(img.size) }}</span>
                  <button class="copy-btn" @click="copyImageToClipboard(img.dataUrl)">ğŸ“‹ å¤åˆ¶å›¾ç‰‡</button>
                </div>
              </div>
            </div>

            <!-- JSON æ•°æ® - å¸¦æŠ˜å çš„ base64 -->
            <div class="json-response">
              <div class="json-header">
                <span>å®Œæ•´å“åº”æ•°æ®</span>
                <button class="toggle-btn" @click="showFullBase64 = !showFullBase64">
                  {{ showFullBase64 ? 'æŠ˜å  Base64' : 'å±•å¼€ Base64' }}
                </button>
              </div>
              <pre>{{ getDisplayResponse() }}</pre>
            </div>
          </div>

          <!-- æµå¼å“åº” -->
          <div v-if="streamChunks.length > 0" class="streaming-display">
            <h4>æµå¼å“åº” ({{ streamChunks.length }} chunks)</h4>
            <div class="stream-chunks">
              <div v-for="chunk in streamChunks" :key="chunk.index" class="chunk-item">
                <div class="chunk-header">
                  <span class="chunk-index">Chunk #{{ chunk.index + 1 }}</span>
                  <span class="chunk-time">{{ formatTime(chunk.timestamp) }}</span>
                </div>
                <pre class="chunk-data">{{ chunk.rawData }}</pre>
              </div>
            </div>
          </div>

          <!-- é”™è¯¯å±•ç¤º -->
          <div v-if="error" class="error-display">
            <h4>âŒ é”™è¯¯</h4>
            <pre>{{ error }}</pre>
          </div>
        </div>
      </div>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, computed, watch, onMounted, onUnmounted } from 'vue'
import CodeEditor from './CodeEditor.vue'

interface StreamChunk {
  content: string
  timestamp: number
  index: number
  rawData: string  // åŸå§‹ chunk æ•°æ®
}

const config = ref({
  baseUrl: '',
  apiKey: '',
})

const selectedModel = ref('gpt-4')
const testPrompt = ref('Hello! è¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚')
const enableTools = ref(false)
const streamMode = ref(false)
const uploadedImage = ref<string | null>(null)
const codeType = ref<'python' | 'curl'>('python')
const currentCode = ref('')
const response = ref<any>(null)
const streamChunks = ref<StreamChunk[]>([])
const error = ref('')
const loading = ref(false)
const showFullBase64 = ref(false)

// è®¡ç®—å±æ€§
const currentProvider = computed(() => {
  if (selectedModel.value.startsWith('gpt-')) return 'openai'
  if (selectedModel.value.startsWith('claude-')) return 'claude'
  if (selectedModel.value.startsWith('gemini-')) return 'gemini'
  return 'openai'
})

const isImageModel = computed(() => {
  return ['gpt-image-1', 'gemini-2.5-flash-image'].includes(selectedModel.value)
})

const supportsTools = computed(() => {
  return ['gpt-4', 'gpt-4o', 'claude-sonnet-4-5-20250929', 'claude-haiku-4-5-20251001'].includes(selectedModel.value)
})

const supportsStreaming = computed(() => {
  return !isImageModel.value
})

const promptLabel = computed(() => {
  if (isImageModel.value) {
    if (selectedModel.value === 'gpt-image-1' && uploadedImage.value) {
      return 'å›¾åƒç¼–è¾‘æŒ‡ä»¤'
    }
    return 'å›¾åƒæè¿°/ç¼–è¾‘æŒ‡ä»¤'
  }
  return 'æµ‹è¯•æ¶ˆæ¯'
})

const promptPlaceholder = computed(() => {
  if (isImageModel.value) {
    if (selectedModel.value === 'gpt-image-1' && uploadedImage.value) {
      return 'ä¾‹å¦‚: Change the coffee cup to red (å·²ä¸Šä¼ å‚è€ƒå›¾,å°†è¿›è¡Œå›¾åƒç¼–è¾‘)'
    }
    return 'ä¾‹å¦‚: A cute baby sea otter wearing a wizard hat (æ–‡æœ¬ç”Ÿæˆå›¾åƒ)'
  }
  return 'è¾“å…¥æµ‹è¯•æ¶ˆæ¯,ä¾‹å¦‚: Hello!'
})

const editorLanguage = computed(() => {
  return codeType.value === 'python' ? 'python' : 'shell'
})

const canExecute = computed(() => {
  return config.value.baseUrl && config.value.apiKey && testPrompt.value.trim()
})

const responseTitle = computed(() => {
  if (isImageModel.value) return 'ç”Ÿæˆçš„å›¾åƒ:'
  return 'å“åº”ç»“æœ:'
})

const formattedResponse = computed(() => {
  if (!response.value) return ''
  return JSON.stringify(response.value, null, 2)
})

// æå–å“åº”ä¸­çš„å›¾ç‰‡æ•°æ®
const responseImages = computed(() => {
  if (!response.value) return []
  const images: Array<{ dataUrl: string; mimeType: string; size: number }> = []

  try {
    // Gemini å›¾åƒå“åº”æ ¼å¼
    if (response.value.candidates) {
      for (const candidate of response.value.candidates) {
        if (candidate.content?.parts) {
          for (const part of candidate.content.parts) {
            if (part.inlineData && part.inlineData.data) {
              const mimeType = part.inlineData.mimeType || 'image/png'
              const base64Data = part.inlineData.data
              const dataUrl = `data:${mimeType};base64,${base64Data}`
              images.push({
                dataUrl,
                mimeType,
                size: base64Data.length
              })
            }
          }
        }
      }
    }

    // OpenAI å›¾åƒå“åº”æ ¼å¼ (url æˆ– b64_json)
    if (response.value.data && Array.isArray(response.value.data)) {
      for (const item of response.value.data) {
        // b64_json æ ¼å¼
        if (item.b64_json) {
          const dataUrl = `data:image/png;base64,${item.b64_json}`
          images.push({
            dataUrl,
            mimeType: 'image/png',
            size: item.b64_json.length
          })
        }
        // url æ ¼å¼
        else if (item.url) {
          images.push({
            dataUrl: item.url,
            mimeType: 'image/png',
            size: 0
          })
        }
        // revised_prompt å­—æ®µ (OpenAI æ–°æ ¼å¼)
        else if (item.revised_prompt && item.url) {
          images.push({
            dataUrl: item.url,
            mimeType: 'image/png',
            size: 0
          })
        }
      }
    }

    // å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°å›¾ç‰‡,å°è¯•æ·±åº¦æœç´¢
    if (images.length === 0 && isImageModel.value) {
      console.log('No images found, response:', response.value)
    }
  } catch (e) {
    console.error('Error extracting images:', e, response.value)
  }

  return images
})

// æ ¼å¼åŒ–å­—èŠ‚å¤§å°
function formatBytes(bytes: number) {
  if (bytes === 0) return '0 Bytes'
  const k = 1024
  const sizes = ['Bytes', 'KB', 'MB']
  const i = Math.floor(Math.log(bytes) / Math.log(k))
  return Math.round(bytes / Math.pow(k, i) * 100) / 100 + ' ' + sizes[i]
}

// è·å–æ˜¾ç¤ºçš„å“åº”æ•°æ®(å¯æŠ˜å  base64)
function getDisplayResponse() {
  if (!response.value) return ''

  if (showFullBase64.value) {
    // æ˜¾ç¤ºå®Œæ•´æ•°æ®
    return JSON.stringify(response.value, null, 2)
  } else {
    // æŠ˜å  base64 æ•°æ®
    const clone = JSON.parse(JSON.stringify(response.value))

    // éå†å¹¶æˆªæ–­ base64 æ•°æ®
    function truncateBase64(obj: any) {
      if (typeof obj !== 'object' || obj === null) return

      for (const key in obj) {
        if (key === 'data' && typeof obj[key] === 'string' && obj[key].length > 100) {
          // æˆªæ–­ base64 æ•°æ®
          obj[key] = obj[key].substring(0, 50) + '... [' + obj[key].length + ' chars] ...' + obj[key].substring(obj[key].length - 50)
        } else if (typeof obj[key] === 'object') {
          truncateBase64(obj[key])
        }
      }
    }

    truncateBase64(clone)
    return JSON.stringify(clone, null, 2)
  }
}

// å¤åˆ¶å›¾ç‰‡åˆ°å‰ªè´´æ¿
async function copyImageToClipboard(dataUrl: string) {
  try {
    // å°† data URL è½¬æ¢ä¸º Blob
    const response = await fetch(dataUrl)
    const blob = await response.blob()

    // å¤åˆ¶åˆ°å‰ªè´´æ¿
    await navigator.clipboard.write([
      new ClipboardItem({ [blob.type]: blob })
    ])

    alert('å›¾ç‰‡å·²å¤åˆ¶åˆ°å‰ªè´´æ¿!')
  } catch (e) {
    console.error('Failed to copy image:', e)
    alert('å¤åˆ¶å¤±è´¥,è¯·æ‰‹åŠ¨ä¿å­˜å›¾ç‰‡')
  }
}

// ç›‘å¬å˜åŒ–è‡ªåŠ¨ç”Ÿæˆä»£ç 
watch([selectedModel, testPrompt, enableTools, streamMode, codeType, uploadedImage, () => config.value], () => {
  generateCode()
}, { deep: true })

// æ ‡å‡†åŒ– Base URL - ç§»é™¤æœ«å°¾çš„ /v1 æˆ– /
function normalizeBaseUrl(url: string): string {
  if (!url) return url
  // ç§»é™¤æœ«å°¾çš„æ–œæ 
  url = url.replace(/\/+$/, '')
  // å¦‚æœä»¥ /v1 æˆ– /v1beta ç»“å°¾,ç§»é™¤å®ƒ
  if (url.endsWith('/v1') || url.endsWith('/v1beta')) {
    url = url.substring(0, url.lastIndexOf('/'))
  }
  return url
}

// ä¸º OpenAI API æ·»åŠ  /v1 è·¯å¾„ (ç”¨äºä»£ç ç¤ºä¾‹)
function getOpenAIBaseUrl(baseUrl: string): string {
  if (!baseUrl) return baseUrl
  // å¦‚æœå·²ç»åŒ…å« /v1,ä¸é‡å¤æ·»åŠ 
  if (baseUrl.endsWith('/v1')) return baseUrl
  // ç§»é™¤æœ«å°¾æ–œæ åæ·»åŠ  /v1
  return baseUrl.replace(/\/+$/, '') + '/v1'
}

// ä» localStorage åŠ è½½é…ç½®
function loadConfig() {
  const saved = localStorage.getItem('llm-api-config')
  if (saved) {
    try {
      const parsed = JSON.parse(saved)
      config.value.baseUrl = normalizeBaseUrl(parsed.baseUrl || '')
      config.value.apiKey = parsed.apiKey || ''
    } catch (e) {
      console.error('Failed to load config:', e)
    }
  }
}

// ç›‘å¬å¯¼èˆªæ é…ç½®æ›´æ–°äº‹ä»¶
function handleConfigUpdate(event: CustomEvent) {
  config.value.baseUrl = normalizeBaseUrl(event.detail.baseUrl || '')
  config.value.apiKey = event.detail.apiKey || ''
}

onMounted(() => {
  loadConfig()
  generateCode()
  window.addEventListener('api-config-updated', handleConfigUpdate as EventListener)
})

onUnmounted(() => {
  window.removeEventListener('api-config-updated', handleConfigUpdate as EventListener)
})

function formatTime(timestamp: number) {
  const date = new Date(timestamp)
  return date.toLocaleTimeString('zh-CN', {
    hour12: false,
    hour: '2-digit',
    minute: '2-digit',
    second: '2-digit',
    fractionalSecondDigits: 3
  })
}

function handleImageUpload(event: Event) {
  const file = (event.target as HTMLInputElement).files?.[0]
  if (file) {
    const reader = new FileReader()
    reader.onload = (e) => {
      uploadedImage.value = e.target?.result as string
    }
    reader.readAsDataURL(file)
  }
}

function generateCode() {
  if (codeType.value === 'python') {
    currentCode.value = generatePythonCode()
  } else {
    currentCode.value = generateCurlCode()
  }
}

function generatePythonCode() {
  const rawBaseUrl = config.value.baseUrl || 'YOUR_BASE_URL'
  const apiKey = config.value.apiKey || 'YOUR_API_KEY'
  const model = selectedModel.value
  const prompt = testPrompt.value

  // GPT-5 (Responses API)
  if (model === 'gpt-5') {
    const baseUrl = getOpenAIBaseUrl(rawBaseUrl)
    if (streamMode.value) {
      return `from openai import OpenAI

# é…ç½®å®¢æˆ·ç«¯
client = OpenAI(
    base_url="${baseUrl}",
    api_key="${apiKey}"
)

# æµå¼è¯·æ±‚ (Responses API)
response = client.responses.create(
    model="gpt-5",
    input="${prompt}",
    stream=True
)

# æµå¼è¾“å‡º
for chunk in response:
    if chunk.text:
        print(chunk.text, end="", flush=True)
print()  # æ¢è¡Œ`
    } else {
      return `from openai import OpenAI

# é…ç½®å®¢æˆ·ç«¯
client = OpenAI(
    base_url="${baseUrl}",
    api_key="${apiKey}"
)

# å‘èµ·è¯·æ±‚ (Responses API)
response = client.responses.create(
    model="gpt-5",
    input="${prompt}"
)

# æ‰“å°ç»“æœ
print(response.output_text)`
    }
  }

  // GPT-Image-1 (DALL-E)
  if (model === 'gpt-image-1') {
    const baseUrl = getOpenAIBaseUrl(rawBaseUrl)
    if (uploadedImage.value) {
      // å›¾åƒç¼–è¾‘æ¨¡å¼
      return `from openai import OpenAI

# é…ç½®å®¢æˆ·ç«¯
client = OpenAI(
    base_url="${baseUrl}",
    api_key="${apiKey}"
)

# å›¾åƒç¼–è¾‘ - åŸºäºå‚è€ƒå›¾ç”Ÿæˆ
with open("input_image.png", "rb") as image_file:
    response = client.images.edit(
        model="gpt-image-1",
        image=image_file,
        prompt="${prompt}",
        size="1024x1024",
        quality="high",  # å¯é€‰: "standard" æˆ– "high"
        n=1,
        response_format="b64_json"  # æˆ– "url"
    )

# å¤„ç†è¿”å›çš„å›¾åƒ
if response.data[0].b64_json:
    import base64
    image_data = base64.b64decode(response.data[0].b64_json)
    with open("edited_image.png", "wb") as f:
        f.write(image_data)
    print("å›¾åƒå·²ä¿å­˜ä¸º edited_image.png")
else:
    print(f"å›¾åƒ URL: {response.data[0].url}")`
    } else {
      // æ–‡ç”Ÿå›¾æ¨¡å¼
      return `from openai import OpenAI

# é…ç½®å®¢æˆ·ç«¯
client = OpenAI(
    base_url="${baseUrl}",
    api_key="${apiKey}"
)

# æ–‡æœ¬ç”Ÿæˆå›¾åƒ
response = client.images.generate(
    model="gpt-image-1",
    prompt="${prompt}",
    size="1024x1024",
    quality="high",  # å¯é€‰: "standard" æˆ– "high"
    n=1,
    response_format="b64_json"  # æˆ– "url"
)

# å¤„ç†è¿”å›çš„å›¾åƒ
if response.data[0].b64_json:
    import base64
    image_data = base64.b64decode(response.data[0].b64_json)
    with open("generated_image.png", "wb") as f:
        f.write(image_data)
    print("å›¾åƒå·²ä¿å­˜ä¸º generated_image.png")
else:
    print(f"å›¾åƒ URL: {response.data[0].url}")`
    }
  }

  // Claude
  if (model.startsWith('claude-')) {
    const toolsCode = enableTools.value ? `,
    tools=[
        {
            "name": "get_weather",
            "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”",
            "input_schema": {
                "type": "object",
                "properties": {
                    "city": {"type": "string", "description": "åŸå¸‚åç§°"}
                },
                "required": ["city"]
            }
        }
    ]` : ''

    if (streamMode.value) {
      return `from anthropic import Anthropic

# é…ç½®å®¢æˆ·ç«¯
client = Anthropic(
    base_url="${rawBaseUrl}",
    api_key="${apiKey}"
)

# æµå¼è¯·æ±‚
with client.messages.stream(
    model="${model}",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "${prompt}"}
    ]${toolsCode}
) as stream:
    for text in stream.text_stream:
        print(text, end="", flush=True)
print()  # æ¢è¡Œ`
    } else {
      return `from anthropic import Anthropic

# é…ç½®å®¢æˆ·ç«¯
client = Anthropic(
    base_url="${rawBaseUrl}",
    api_key="${apiKey}"
)

# å‘èµ·è¯·æ±‚
message = client.messages.create(
    model="${model}",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "${prompt}"}
    ]${toolsCode}
)

# æ‰“å°ç»“æœ
print(message.content[0].text)`
    }
  }

  // Gemini
  if (model.startsWith('gemini-')) {
    const isImageGen = model === 'gemini-2.5-flash-image'

    if (isImageGen) {
      return `from google import genai
from google.genai import types

# é…ç½®å®¢æˆ·ç«¯
client = genai.Client(
    api_key="${apiKey}",
    http_options={'api_endpoint': "${baseUrl}"}
)

# å›¾åƒç”Ÿæˆ - åªç”Ÿæˆå›¾åƒ
response = client.models.generate_content(
    model="${model}",
    contents="${prompt}",
    config=types.GenerateContentConfig(
        response_modalities=["IMAGE"]  # åªè¿”å›å›¾åƒ
    )
)

# ä¿å­˜ç”Ÿæˆçš„å›¾åƒ
for part in response.candidates[0].content.parts:
    if part.inline_data:
        with open("generated_image.png", "wb") as f:
            f.write(part.inline_data.data)
        print("å›¾åƒå·²ä¿å­˜ä¸º generated_image.png")
        break`
    } else if (streamMode.value) {
      return `from google import genai
from google.genai import types

# é…ç½®å®¢æˆ·ç«¯
client = genai.Client(
    api_key="${apiKey}",
    http_options={'api_endpoint': "${baseUrl}"}
)

# æµå¼è¯·æ±‚
for chunk in client.models.generate_content_stream(
    model="${model}",
    contents="${prompt}",
    config=types.GenerateContentConfig(
        temperature=0.7,
        max_output_tokens=1024
    )
):
    print(chunk.text, end="", flush=True)
print()  # æ¢è¡Œ`
    } else {
      return `from google import genai
from google.genai import types

# é…ç½®å®¢æˆ·ç«¯
client = genai.Client(
    api_key="${apiKey}",
    http_options={'api_endpoint': "${baseUrl}"}
)

# å‘èµ·è¯·æ±‚
response = client.models.generate_content(
    model="${model}",
    contents="${prompt}",
    config=types.GenerateContentConfig(
        temperature=0.7,
        max_output_tokens=1024
    )
)

# æ‰“å°ç»“æœ
print(response.text)`
    }
  }

  // GPT-4/GPT-4o (Chat Completions)
  const baseUrl = getOpenAIBaseUrl(rawBaseUrl)
  const toolsCode = enableTools.value ? `,
    tools=[
        {
            "type": "function",
            "function": {
                "name": "get_weather",
                "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "city": {"type": "string", "description": "åŸå¸‚åç§°"}
                    },
                    "required": ["city"]
                }
            }
        }
    ]` : ''

  if (streamMode.value) {
    return `from openai import OpenAI

# é…ç½®å®¢æˆ·ç«¯
client = OpenAI(
    base_url="${baseUrl}",
    api_key="${apiKey}"
)

# æµå¼è¯·æ±‚
stream = client.chat.completions.create(
    model="${model}",
    messages=[
        {"role": "user", "content": "${prompt}"}
    ],
    stream=True${toolsCode}
)

# æµå¼è¾“å‡º
for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
print()  # æ¢è¡Œ`
  } else {
    return `from openai import OpenAI

# é…ç½®å®¢æˆ·ç«¯
client = OpenAI(
    base_url="${baseUrl}",
    api_key="${apiKey}"
)

# å‘èµ·è¯·æ±‚
response = client.chat.completions.create(
    model="${model}",
    messages=[
        {"role": "user", "content": "${prompt}"}
    ]${toolsCode}
)

# æ‰“å°ç»“æœ
print(response.choices[0].message.content)`
  }
}

function generateCurlCode() {
  const rawBaseUrl = config.value.baseUrl || 'YOUR_BASE_URL'
  const apiKey = config.value.apiKey || 'YOUR_API_KEY'
  const model = selectedModel.value
  const prompt = testPrompt.value

  // GPT-5 (Responses API)
  if (model === 'gpt-5') {
    const baseUrl = getOpenAIBaseUrl(rawBaseUrl)
    const streamParam = streamMode.value ? ',\n    "stream": true' : ''
    return `curl ${baseUrl}/v1/responses \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer ${apiKey}" \\
  -d '{
    "model": "gpt-5",
    "input": "${prompt}"${streamParam}
  }'`
  }

  // GPT-Image-1
  if (model === 'gpt-image-1') {
    const baseUrl = getOpenAIBaseUrl(rawBaseUrl)
    if (uploadedImage.value) {
      // å›¾åƒç¼–è¾‘æ¨¡å¼ - ä½¿ç”¨ multipart/form-data
      return `curl ${baseUrl}/v1/images/edits \\
  -H "Authorization: Bearer ${apiKey}" \\
  -F "model=gpt-image-1" \\
  -F "image=@input_image.png" \\
  -F "prompt=${prompt}" \\
  -F "size=1024x1024" \\
  -F "quality=high" \\
  -F "n=1" \\
  -F "response_format=b64_json"`
    } else {
      // æ–‡ç”Ÿå›¾æ¨¡å¼
      return `curl ${baseUrl}/v1/images/generations \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer ${apiKey}" \\
  -d '{
    "model": "gpt-image-1",
    "prompt": "${prompt}",
    "size": "1024x1024",
    "quality": "high",
    "n": 1,
    "response_format": "b64_json"
  }'`
    }
  }

  // Claude
  if (model.startsWith('claude-')) {
    const streamParam = streamMode.value ? ',\n    "stream": true' : ''
    const toolsParam = enableTools.value ? `,\n    "tools": [
      {
        "name": "get_weather",
        "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”",
        "input_schema": {
          "type": "object",
          "properties": {
            "city": {"type": "string", "description": "åŸå¸‚åç§°"}
          },
          "required": ["city"]
        }
      }
    ]` : ''
    return `curl ${rawBaseUrl}/v1/messages \\
  -H "Content-Type: application/json" \\
  -H "x-api-key: ${apiKey}" \\
  -H "anthropic-version: 2023-06-01" \\
  -d '{
    "model": "${model}",
    "max_tokens": 1024,
    "messages": [
      {"role": "user", "content": "${prompt}"}
    ]${streamParam}${toolsParam}
  }'`
  }

  // Gemini
  if (model.startsWith('gemini-')) {
    const isImageGen = model === 'gemini-2.5-flash-image'
    const endpoint = streamMode.value ? 'streamGenerateContent' : 'generateContent'

    if (isImageGen) {
      // å›¾åƒç”Ÿæˆ - åªè¿”å›å›¾åƒ
      return `curl "${baseUrl}/v1beta/models/${model}:${endpoint}?key=${apiKey}" \\
  -H "Content-Type: application/json" \\
  -d '{
    "contents": [{
      "parts": [{"text": "${prompt}"}]
    }],
    "generationConfig": {
      "temperature": 0.7,
      "maxOutputTokens": 1024,
      "response_modalities": ["IMAGE"]
    }
  }'`
    } else {
      // æ–‡æœ¬ç”Ÿæˆ
      const altParam = streamMode.value ? '&alt=sse' : ''
      return `curl "${baseUrl}/v1beta/models/${model}:${endpoint}?key=${apiKey}${altParam}" \\
  -H "Content-Type: application/json" \\
  -d '{
    "contents": [{
      "parts": [{"text": "${prompt}"}]
    }],
    "generationConfig": {
      "temperature": 0.7,
      "maxOutputTokens": 1024
    }
  }'`
    }
  }

  // GPT-4/GPT-4o
  const baseUrl = getOpenAIBaseUrl(rawBaseUrl)
  const streamParam = streamMode.value ? ',\n    "stream": true' : ''
  const toolsParam = enableTools.value ? `,\n    "tools": [
      {
        "type": "function",
        "function": {
          "name": "get_weather",
          "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”",
          "parameters": {
            "type": "object",
            "properties": {
              "city": {"type": "string", "description": "åŸå¸‚åç§°"}
            },
            "required": ["city"]
          }
        }
      }
    ]` : ''

  return `curl ${baseUrl}/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer ${apiKey}" \\
  -d '{
    "model": "${model}",
    "messages": [
      {"role": "user", "content": "${prompt}"}
    ]${streamParam}${toolsParam}
  }'`
}

async function executeTest() {
  if (!canExecute.value) {
    error.value = 'è¯·å…ˆé…ç½® Base URLã€API Key å¹¶è¾“å…¥æµ‹è¯•æ¶ˆæ¯!'
    return
  }

  loading.value = true
  response.value = null
  streamChunks.value = []
  error.value = ''

  try {
    // æ ¹æ®æ¨¡å‹ç±»å‹æ‰§è¡Œä¸åŒçš„è¯·æ±‚
    const model = selectedModel.value

    if (model === 'gpt-5') {
      await executeGPT5Request()
    } else if (model === 'gpt-image-1') {
      await executeImageGeneration()
    } else if (model.startsWith('claude-')) {
      await executeClaudeRequest()
    } else if (model.startsWith('gemini-')) {
      await executeGeminiRequest()
    } else {
      // GPT-4/GPT-4o
      await executeGPTRequest()
    }
  } catch (e: any) {
    error.value = e.message || 'æœªçŸ¥é”™è¯¯'
  } finally {
    loading.value = false
  }
}

// GPT-5 Responses API
async function executeGPT5Request() {
  const baseUrl = getOpenAIBaseUrl(config.value.baseUrl)
  const url = `${baseUrl}/v1/responses`
  const payload: any = {
    model: 'gpt-5',
    input: testPrompt.value
  }

  if (streamMode.value) {
    payload.stream = true
  }

  const fetchResponse = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${config.value.apiKey}`
    },
    body: JSON.stringify(payload)
  })

  if (!fetchResponse.ok) {
    const errorText = await fetchResponse.text()
    throw new Error(`HTTP ${fetchResponse.status}: ${errorText}`)
  }

  if (streamMode.value) {
    await handleStreamResponse(fetchResponse, 'openai')
  } else {
    response.value = await fetchResponse.json()
  }
}

// å›¾åƒç”Ÿæˆæˆ–ç¼–è¾‘
async function executeImageGeneration() {
  const baseUrl = getOpenAIBaseUrl(config.value.baseUrl)

  // å¦‚æœæœ‰ä¸Šä¼ å›¾ç‰‡,ä½¿ç”¨ç¼–è¾‘æ¨¡å¼
  if (uploadedImage.value) {
    const url = `${baseUrl}/v1/images/edits`

    // å°† base64 è½¬æ¢ä¸º Blob
    const base64Data = uploadedImage.value.split(',')[1]
    const byteCharacters = atob(base64Data)
    const byteArrays = []
    for (let i = 0; i < byteCharacters.length; i++) {
      byteArrays.push(byteCharacters.charCodeAt(i))
    }
    const blob = new Blob([new Uint8Array(byteArrays)], { type: 'image/png' })

    // æ„å»º FormData
    const formData = new FormData()
    formData.append('model', selectedModel.value)
    formData.append('image', blob, 'input_image.png')
    formData.append('prompt', testPrompt.value)
    formData.append('size', '1024x1024')
    formData.append('quality', 'high')
    formData.append('n', '1')
    formData.append('response_format', 'b64_json')

    console.log('Image edit request:', { url, prompt: testPrompt.value })

    const fetchResponse = await fetch(url, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${config.value.apiKey}`
      },
      body: formData
    })

    if (!fetchResponse.ok) {
      const errorText = await fetchResponse.text()
      throw new Error(`HTTP ${fetchResponse.status}: ${errorText}`)
    }

    const result = await fetchResponse.json()
    console.log('Image edit response:', result)
    response.value = result

    if (!result.data || result.data.length === 0) {
      error.value = 'å“åº”ä¸­æ²¡æœ‰å›¾ç‰‡æ•°æ®,è¯·æ£€æŸ¥ API é…ç½®'
    } else if (!result.data[0].url && !result.data[0].b64_json) {
      error.value = 'å›¾ç‰‡æ•°æ®æ ¼å¼ä¸æ­£ç¡®'
    }
  } else {
    // æ–‡ç”Ÿå›¾æ¨¡å¼
    const url = `${baseUrl}/v1/images/generations`
    const payload = {
      model: selectedModel.value,
      prompt: testPrompt.value,
      size: '1024x1024',
      quality: 'high',
      n: 1,
      response_format: 'b64_json'
    }

    console.log('Image generation request:', { url, payload })

    const fetchResponse = await fetch(url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${config.value.apiKey}`
      },
      body: JSON.stringify(payload)
    })

    if (!fetchResponse.ok) {
      const errorText = await fetchResponse.text()
      throw new Error(`HTTP ${fetchResponse.status}: ${errorText}`)
    }

    const result = await fetchResponse.json()
    console.log('Image generation response:', result)
    response.value = result

    if (!result.data || result.data.length === 0) {
      error.value = 'å“åº”ä¸­æ²¡æœ‰å›¾ç‰‡æ•°æ®,è¯·æ£€æŸ¥ API é…ç½®'
    } else if (!result.data[0].url && !result.data[0].b64_json) {
      error.value = 'å›¾ç‰‡æ•°æ®æ ¼å¼ä¸æ­£ç¡®'
    }
  }
}

// GPT-4/GPT-4o
async function executeGPTRequest() {
  const baseUrl = getOpenAIBaseUrl(config.value.baseUrl)
  const url = `${baseUrl}/v1/chat/completions`
  const payload: any = {
    model: selectedModel.value,
    messages: [{ role: 'user', content: testPrompt.value }]
  }

  if (streamMode.value) {
    payload.stream = true
  }

  if (enableTools.value) {
    payload.tools = [
      {
        type: 'function',
        function: {
          name: 'get_weather',
          description: 'è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”',
          parameters: {
            type: 'object',
            properties: {
              city: { type: 'string', description: 'åŸå¸‚åç§°' }
            },
            required: ['city']
          }
        }
      }
    ]
  }

  const fetchResponse = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${config.value.apiKey}`
    },
    body: JSON.stringify(payload)
  })

  if (!fetchResponse.ok) {
    const errorText = await fetchResponse.text()
    throw new Error(`HTTP ${fetchResponse.status}: ${errorText}`)
  }

  if (streamMode.value) {
    await handleStreamResponse(fetchResponse, 'openai')
  } else {
    response.value = await fetchResponse.json()
  }
}

// Claude
async function executeClaudeRequest() {
  const url = `${config.value.baseUrl}/v1/messages`
  const payload: any = {
    model: selectedModel.value,
    max_tokens: 1024,
    messages: [{ role: 'user', content: testPrompt.value }]
  }

  if (streamMode.value) {
    payload.stream = true
  }

  if (enableTools.value) {
    payload.tools = [
      {
        name: 'get_weather',
        description: 'è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”',
        input_schema: {
          type: 'object',
          properties: {
            city: { type: 'string', description: 'åŸå¸‚åç§°' }
          },
          required: ['city']
        }
      }
    ]
  }

  const fetchResponse = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-api-key': config.value.apiKey,
      'anthropic-version': '2023-06-01'
    },
    body: JSON.stringify(payload)
  })

  if (!fetchResponse.ok) {
    const errorText = await fetchResponse.text()
    throw new Error(`HTTP ${fetchResponse.status}: ${errorText}`)
  }

  if (streamMode.value) {
    await handleStreamResponse(fetchResponse, 'claude')
  } else {
    response.value = await fetchResponse.json()
  }
}

// Gemini
async function executeGeminiRequest() {
  const endpoint = streamMode.value ? 'streamGenerateContent' : 'generateContent'
  // Gemini æµå¼éœ€è¦æ·»åŠ  alt=sse å‚æ•°
  const altParam = streamMode.value ? '&alt=sse' : ''
  const url = `${config.value.baseUrl}/v1beta/models/${selectedModel.value}:${endpoint}?key=${config.value.apiKey}${altParam}`

  const payload = {
    contents: [{
      parts: [{ text: testPrompt.value }]
    }],
    generationConfig: {
      temperature: 0.7,
      maxOutputTokens: 1024
    }
  }

  const fetchResponse = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(payload)
  })

  if (!fetchResponse.ok) {
    const errorText = await fetchResponse.text()
    throw new Error(`HTTP ${fetchResponse.status}: ${errorText}`)
  }

  if (streamMode.value) {
    await handleStreamResponse(fetchResponse, 'gemini')
  } else {
    response.value = await fetchResponse.json()
  }
}

// å¤„ç†æµå¼å“åº”
async function handleStreamResponse(fetchResponse: Response, provider: 'openai' | 'claude' | 'gemini') {
  const reader = fetchResponse.body!.getReader()
  const decoder = new TextDecoder()
  let buffer = '' // ç”¨äºå¤„ç†è·¨ chunk çš„æ•°æ®

  while (true) {
    const { done, value } = await reader.read()
    if (done) {
      // æµç»“æŸ,æ·»åŠ ç»“æŸæ ‡è®°
      if (streamChunks.value.length > 0) {
        streamChunks.value.push({
          content: '[STREAM_END]',
          timestamp: Date.now(),
          index: streamChunks.value.length,
          rawData: '{"streamEnd": true}'
        })
      }
      break
    }

    buffer += decoder.decode(value, { stream: true })
    const lines = buffer.split('\n')
    buffer = lines.pop() || '' // ä¿ç•™æœ€åä¸€ä¸ªä¸å®Œæ•´çš„è¡Œ

    for (const line of lines) {
      if (!line.trim()) continue

      if (line.startsWith('data: ')) {
        const data = line.slice(6).trim()
        if (data === '[DONE]') {
          streamChunks.value.push({
            content: '[DONE]',
            timestamp: Date.now(),
            index: streamChunks.value.length,
            rawData: 'data: [DONE]'
          })
          return
        }

        try {
          const json = JSON.parse(data)
          let content = ''

          if (provider === 'openai') {
            content = json.choices?.[0]?.delta?.content || json.text || ''
          } else if (provider === 'claude') {
            if (json.type === 'content_block_delta') {
              content = json.delta?.text || ''
            }
          } else if (provider === 'gemini') {
            // Gemini å¯èƒ½æœ‰å¤šç§æ ¼å¼
            content = json.candidates?.[0]?.content?.parts?.[0]?.text ||
                     json.text ||
                     ''
          }

          // ä¿å­˜åŸå§‹ chunk å’Œæå–çš„ content
          streamChunks.value.push({
            content: content || '(empty)',
            timestamp: Date.now(),
            index: streamChunks.value.length,
            rawData: JSON.stringify(json, null, 2)
          })
        } catch (e) {
          console.error('Parse error:', e, 'Data:', data)
          streamChunks.value.push({
            content: '(parse error)',
            timestamp: Date.now(),
            index: streamChunks.value.length,
            rawData: data
          })
        }
      } else if (line.trim().startsWith('{')) {
        // æŸäº› API å¯èƒ½ä¸ä½¿ç”¨ "data: " å‰ç¼€
        try {
          const json = JSON.parse(line)
          let content = ''

          if (provider === 'gemini') {
            content = json.candidates?.[0]?.content?.parts?.[0]?.text || json.text || ''
          }

          if (content || Object.keys(json).length > 0) {
            streamChunks.value.push({
              content: content || '(no text)',
              timestamp: Date.now(),
              index: streamChunks.value.length,
              rawData: JSON.stringify(json, null, 2)
            })
          }
        } catch (e) {
          // å¿½ç•¥é JSON è¡Œ
        }
      }
    }
  }
}
</script>

<style scoped>
.unified-playground {
  margin: 1rem auto;
  padding: 0 1rem;
  max-width: 1400px;
  width: 100%;
  box-sizing: border-box;
}

.unified-playground h2 {
  margin-bottom: 1rem;
  padding: 0 0.5rem;
  color: var(--vp-c-brand);
}

/* ä¸‰æ å¸ƒå±€ */
.three-column-layout {
  display: grid;
  grid-template-columns: 280px 1fr 380px;
  gap: 1rem;
  margin-top: 1rem;
  min-height: 600px;
  width: 100%;
}

/* é¢æ¿é€šç”¨æ ·å¼ */
.left-panel,
.middle-panel,
.right-panel {
  background: var(--vp-c-bg-soft);
  border: 1px solid var(--vp-c-divider);
  border-radius: 8px;
  overflow: hidden;
  display: flex;
  flex-direction: column;
}

.panel-header {
  background: var(--vp-c-brand);
  color: white;
  padding: 0.75rem 1rem;
  font-weight: 600;
  font-size: 14px;
  display: flex;
  justify-content: space-between;
  align-items: center;
}

/* å·¦ä¾§é…ç½®åŒº */
.left-panel {
  padding-bottom: 1rem;
}

.config-section {
  padding: 1rem;
  border-bottom: 1px solid var(--vp-c-divider);
}

.config-section:last-child {
  border-bottom: none;
}

.config-label {
  display: block;
  font-size: 13px;
  font-weight: 500;
  color: var(--vp-c-text-1);
  margin-bottom: 0.5rem;
}

.config-select {
  width: 100%;
  padding: 0.5rem;
  border: 1px solid var(--vp-c-divider);
  border-radius: 6px;
  background: var(--vp-c-bg);
  color: var(--vp-c-text-1);
  font-size: 13px;
  cursor: pointer;
  transition: border-color 0.2s;
}

.config-select:hover {
  border-color: var(--vp-c-brand);
}

.config-select:focus {
  outline: none;
  border-color: var(--vp-c-brand);
  box-shadow: 0 0 0 3px rgba(var(--vp-c-brand-rgb), 0.1);
}

.config-checkbox {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  cursor: pointer;
  user-select: none;
  font-size: 13px;
}

.config-checkbox input[type="checkbox"] {
  width: 16px;
  height: 16px;
  cursor: pointer;
}

.config-file {
  width: 100%;
  padding: 0.5rem;
  border: 1px solid var(--vp-c-divider);
  border-radius: 6px;
  background: var(--vp-c-bg);
  color: var(--vp-c-text-1);
  font-size: 12px;
}

.config-textarea {
  width: 100%;
  padding: 0.5rem;
  border: 1px solid var(--vp-c-divider);
  border-radius: 6px;
  background: var(--vp-c-bg);
  color: var(--vp-c-text-1);
  font-size: 13px;
  font-family: var(--vp-font-family-mono);
  resize: vertical;
  transition: border-color 0.2s;
}

.config-textarea:hover {
  border-color: var(--vp-c-brand);
}

.config-textarea:focus {
  outline: none;
  border-color: var(--vp-c-brand);
  box-shadow: 0 0 0 3px rgba(var(--vp-c-brand-rgb), 0.1);
}

/* ä¸­é—´ä»£ç åŒº */
.middle-panel {
  min-width: 500px;
  /* è°ƒè¯•ç”¨:ç¡®ä¿å¯è§ */
}

.code-container {
  flex: 1;
  overflow: hidden;
  min-height: 400px;
  background: var(--vp-c-bg);
}

/* å³ä¾§ç»“æœåŒº */
.result-container {
  flex: 1;
  overflow-y: auto;
  padding: 1rem;
}

.empty-state {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  height: 100%;
  color: var(--vp-c-text-2);
}

.empty-icon {
  font-size: 48px;
  margin-bottom: 1rem;
}

.empty-state p {
  font-size: 14px;
}

.tab-switcher {
  display: flex;
  gap: 0.25rem;
}

.tab-button {
  padding: 0.25rem 0.75rem;
  border: none;
  background: rgba(255, 255, 255, 0.1);
  color: white;
  border-radius: 4px;
  cursor: pointer;
  transition: all 0.2s;
  font-size: 12px;
  font-weight: 500;
}

.tab-button:hover {
  background: rgba(255, 255, 255, 0.2);
}

.tab-button.active {
  background: rgba(255, 255, 255, 0.3);
}

.btn {
  width: 100%;
  padding: 0.75rem 1rem;
  border: none;
  background: var(--vp-c-brand);
  color: white;
  border-radius: 6px;
  cursor: pointer;
  transition: all 0.2s;
  font-size: 14px;
  font-weight: 600;
}

.btn:hover:not(:disabled) {
  opacity: 0.9;
  transform: translateY(-1px);
  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.15);
}

.btn:active:not(:disabled) {
  transform: translateY(0);
}

.btn:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

.btn-block {
  width: 100%;
}

.response-display,
.streaming-display {
  margin-bottom: 1rem;
}

.response-display:last-child,
.streaming-display:last-child {
  margin-bottom: 0;
}

.response-display h4,
.streaming-display h4 {
  margin: 0 0 0.75rem 0;
  font-size: 14px;
  color: var(--vp-c-text-1);
  font-weight: 600;
}

.response-display pre {
  margin: 0;
  padding: 1rem;
  background: #1e1e1e;
  color: #d4d4d4;
  border-radius: 6px;
  overflow-x: auto;
  font-size: 12px;
  line-height: 1.5;
  max-height: 500px;
  overflow-y: auto;
}

/* å›¾ç‰‡é¢„è§ˆ */
.image-preview-container {
  margin-bottom: 1rem;
}

.image-preview-item {
  margin-bottom: 1rem;
}

.generated-image {
  max-width: 100%;
  max-height: 400px;
  height: auto;
  border-radius: 8px;
  border: 1px solid var(--vp-c-divider);
  display: block;
  margin-bottom: 0.5rem;
  object-fit: contain;
}

.image-info {
  display: flex;
  align-items: center;
  gap: 1rem;
  font-size: 12px;
  color: var(--vp-c-text-2);
  padding: 0.5rem;
  background: var(--vp-c-bg-soft);
  border-radius: 4px;
}

.image-info span {
  font-family: var(--vp-font-family-mono);
}

.copy-btn {
  margin-left: auto;
  padding: 0.25rem 0.75rem;
  background: var(--vp-c-brand);
  color: white;
  border: none;
  border-radius: 4px;
  cursor: pointer;
  font-size: 11px;
  transition: opacity 0.2s;
}

.copy-btn:hover {
  opacity: 0.8;
}

/* JSON å“åº” */
.json-response {
  margin-top: 1rem;
}

.json-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 0.5rem;
  padding: 0.5rem;
  background: var(--vp-c-bg-soft);
  border-radius: 4px;
}

.json-header span {
  font-size: 13px;
  font-weight: 500;
  color: var(--vp-c-text-1);
}

.toggle-btn {
  padding: 0.25rem 0.75rem;
  background: var(--vp-c-bg);
  color: var(--vp-c-text-1);
  border: 1px solid var(--vp-c-divider);
  border-radius: 4px;
  cursor: pointer;
  font-size: 11px;
  transition: all 0.2s;
}

.toggle-btn:hover {
  background: var(--vp-c-bg-mute);
}

.stream-chunks {
  max-height: 500px;
  overflow-y: auto;
}

.chunk-item {
  margin-bottom: 0.75rem;
  padding: 0.75rem;
  background: var(--vp-c-bg);
  border: 1px solid var(--vp-c-divider);
  border-radius: 6px;
  transition: box-shadow 0.2s;
}

.chunk-item:hover {
  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
}

.chunk-item:last-child {
  margin-bottom: 0;
}

.chunk-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 0.5rem;
  padding-bottom: 0.5rem;
  border-bottom: 1px solid var(--vp-c-divider);
}

.chunk-index {
  font-weight: 600;
  color: var(--vp-c-brand);
  font-size: 12px;
}

.chunk-time {
  font-size: 11px;
  color: var(--vp-c-text-2);
  font-family: var(--vp-font-family-mono);
}

.chunk-data {
  margin: 0;
  padding: 0.5rem;
  background: #1e1e1e;
  color: #d4d4d4;
  border-radius: 4px;
  overflow-x: auto;
  font-size: 11px;
  line-height: 1.5;
  max-height: 300px;
  overflow-y: auto;
}

.error-display {
  padding: 1rem;
  background: #fee;
  border: 1px solid #f66;
  border-radius: 6px;
  color: #c00;
}

.error-display h4 {
  margin: 0 0 0.5rem 0;
  font-size: 14px;
  font-weight: 600;
}

.error-display pre {
  margin: 0;
  padding: 0.5rem;
  background: #fdd;
  border-radius: 4px;
  white-space: pre-wrap;
  word-break: break-word;
  font-size: 12px;
  line-height: 1.5;
}
</style>
